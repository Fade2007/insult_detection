{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../Preprocessed Data/cleaned_dataset_train.csv')\n",
    "df_test = pd.read_csv('../Preprocessed Data//cleaned_dataset_test.csv')\n",
    "#df = pd.read_csv('../cleaned_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['comment'].fillna(\" \").tolist()\n",
    "Y_train = df_train['insult'].tolist()\n",
    "\n",
    "X_test = df_test['comment'].fillna(\" \").tolist()\n",
    "Y_test = df_test['insult'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasYourMom(sentence):\n",
    "    return sentence.lower().count(\"your mom\")\n",
    "\n",
    "def wordCount(sentence):\n",
    "    return len(sentence.split())\n",
    "\n",
    "def countUpper(sentence):\n",
    "    return float(sum(1 for k in sentence if k.isupper()))/len(sentence)\n",
    "\n",
    "def countExclaim(sentence):\n",
    "    return float(sentence.count('!')/float(len(sentence)))\n",
    "\n",
    "def countAtTheRate(sentence):\n",
    "    return float(sentence.count('@')/float(len(sentence)))\n",
    "\n",
    "def countPercent(sentence):\n",
    "    return float(sentence.count('%')/float(len(sentence)))\n",
    "\n",
    "def countLeftBracket(sentence):\n",
    "    return float(sentence.count('(')/float(len(sentence)))\n",
    "\n",
    "def countQuotes(sentence):\n",
    "    return float(sentence.count('\"')/float(len(sentence)))\n",
    "\n",
    "def countStar(sentence):\n",
    "    return float(sentence.count('*')/float(len(sentence)))\n",
    "\n",
    "def countBackSlashes(sentence):\n",
    "    return float(sentence.count('\\\\')/float(len(sentence)))\n",
    "\n",
    "def countFrontSlash(sentence):\n",
    "    return float(sentence.count('/')/float(len(sentence)))\n",
    "\n",
    "\n",
    "def countYour(sentence):\n",
    "    s = 0\n",
    "    lst = ['your','Your','YOUR']\n",
    "    for word in lst:\n",
    "        s += sentence.count(word)\n",
    "    return float(s)/len(sentence)\n",
    "\n",
    "def countYou(sentence):\n",
    "    s = 0\n",
    "    lst = ['you','You','YOU']\n",
    "    for word in lst:\n",
    "        s += sentence.count(word)\n",
    "    return float(s)/len(sentence)\n",
    "\n",
    "def countBadWords(sentence):\n",
    "    tmp = sentence.lower()\n",
    "    badWordCount = 0\n",
    "    badWordFile = open(\"../compiled_badword_list.txt\",\"r\")\n",
    "    badWordList = badWordFile.readlines()\n",
    "    for badWord in badWordList:\n",
    "        bw = badWord.lower()\n",
    "        if bw[:-1] in tmp:\n",
    "            badWordCount += 1\n",
    "    return badWordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train['comment'].fillna(\" \").tolist()\n",
    "Y_train = df_train['insult'].tolist()\n",
    "X_test = df_test['comment'].fillna(\" \").tolist()\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train_tfidf = vectorizer.transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf = X_train_tfidf.todense()\n",
    "X_test_tfidf = X_test_tfidf.todense()\n",
    "\n",
    "has_mom = []\n",
    "word_count = []\n",
    "count_upper = []\n",
    "count_exclaim = []\n",
    "count_AtTheRate = []\n",
    "count_percent = []\n",
    "count_LeftBracket = []\n",
    "count_Quotes = []\n",
    "count_Star = []\n",
    "count_BackSlashes = []\n",
    "count_FrontSlash = []\n",
    "count_Your = []\n",
    "count_You = []\n",
    "count_badword = []\n",
    "for sentence in X_train:\n",
    "    has_mom.append(hasYourMom(sentence))\n",
    "    word_count.append(wordCount(sentence))\n",
    "    count_upper.append(countUpper(sentence))\n",
    "    count_exclaim.append(countExclaim(sentence))\n",
    "    count_AtTheRate.append(countAtTheRate(sentence))\n",
    "    count_percent.append(countPercent(sentence))\n",
    "    count_LeftBracket.append(countLeftBracket(sentence))\n",
    "    count_Quotes.append(countQuotes(sentence))\n",
    "    count_Star.append(countStar(sentence))\n",
    "    count_BackSlashes.append(countBackSlashes(sentence))\n",
    "    count_FrontSlash.append(countFrontSlash(sentence))\n",
    "    count_Your.append(countYour(sentence))\n",
    "    count_You.append(countYou(sentence))\n",
    "    count_badword.append(countBadWords(sentence))\n",
    "    \n",
    "    \n",
    "has_mom = np.matrix(has_mom)\n",
    "has_mom = np.transpose(has_mom)\n",
    "word_count = np.matrix(word_count)\n",
    "word_count = np.transpose(word_count)    \n",
    "count_upper = np.matrix(count_upper)\n",
    "count_upper = np.transpose(count_upper) \n",
    "count_exclaim = np.matrix(count_exclaim)\n",
    "count_exclaim = np.transpose(count_exclaim)\n",
    "count_AtTheRate = np.matrix(count_AtTheRate)\n",
    "count_AtTheRate = np.transpose(count_AtTheRate)\n",
    "count_percent = np.matrix(count_percent)\n",
    "count_percent = np.transpose(count_percent)\n",
    "count_LeftBracket = np.matrix(count_LeftBracket)\n",
    "count_LeftBracket = np.transpose(count_LeftBracket)\n",
    "count_Quotes = np.matrix(count_Quotes)\n",
    "count_Quotes = np.transpose(count_Quotes)\n",
    "count_Star = np.matrix(count_Star)\n",
    "count_Star = np.transpose(count_Star)\n",
    "count_BackSlashes = np.matrix(count_BackSlashes)\n",
    "count_BackSlashes = np.transpose(count_BackSlashes)\n",
    "count_FrontSlash = np.matrix(count_FrontSlash)\n",
    "count_FrontSlash = np.transpose(count_FrontSlash)\n",
    "count_Your = np.matrix(count_Your)\n",
    "count_Your = np.transpose(count_Your)\n",
    "count_You = np.matrix(count_You)\n",
    "count_You = np.transpose(count_You)\n",
    "count_badword = np.matrix(count_badword)\n",
    "count_badword = np.transpose(count_badword)\n",
    "\n",
    "X_train_train = np.zeros((3947, 14))\n",
    "\n",
    "for i in [has_mom, word_count, count_upper, count_exclaim, count_AtTheRate, count_percent, count_LeftBracket,\n",
    "         count_Quotes, count_Star, count_BackSlashes, count_FrontSlash, count_Your, count_You, count_badword]:\n",
    "    X_train_tfidf = np.insert(X_train_tfidf, [X_train_tfidf.shape[1]], i, axis=1)\n",
    "    \n",
    "lis = [has_mom, word_count, count_upper, count_exclaim, count_AtTheRate, count_percent, count_LeftBracket,\n",
    "         count_Quotes, count_Star, count_BackSlashes, count_FrontSlash, count_Your, count_You, count_badword]\n",
    "\n",
    "#print(has_mom.shape) \n",
    "print(lis[0][10, 0])\n",
    "for i in range(14):\n",
    "    for j in range(3947):\n",
    "        X_train_train[j, i] = lis[i][j, 0]\n",
    "\n",
    "X_train_train = sparse.csr_matrix(X_train_train)\n",
    "X_train_tfidf = sparse.csr_matrix(X_train_tfidf)\n",
    "\n",
    "has_momT = []\n",
    "word_countT = []\n",
    "count_upperT = []\n",
    "count_exclaimT = []\n",
    "count_AtTheRateT = []\n",
    "count_percentT = []\n",
    "count_LeftBracketT = []\n",
    "count_QuotesT = []\n",
    "count_StarT = []\n",
    "count_BackSlashesT = []\n",
    "count_FrontSlashT = []\n",
    "count_YourT = []\n",
    "count_YouT = []\n",
    "count_badwordT = []\n",
    "for sentence in X_test:\n",
    "    has_momT.append(hasYourMom(sentence))\n",
    "    word_countT.append(wordCount(sentence))\n",
    "    count_upperT.append(countUpper(sentence))\n",
    "    count_exclaimT.append(countExclaim(sentence))\n",
    "    count_AtTheRateT.append(countAtTheRate(sentence))\n",
    "    count_percentT.append(countPercent(sentence))\n",
    "    count_LeftBracketT.append(countLeftBracket(sentence))\n",
    "    count_QuotesT.append(countQuotes(sentence))\n",
    "    count_StarT.append(countStar(sentence))\n",
    "    count_BackSlashesT.append(countBackSlashes(sentence))\n",
    "    count_FrontSlashT.append(countFrontSlash(sentence))\n",
    "    count_YourT.append(countYour(sentence))\n",
    "    count_YouT.append(countYou(sentence))\n",
    "    count_badwordT.append(countBadWords(sentence))\n",
    "    \n",
    "    \n",
    "has_momT = np.matrix(has_momT)\n",
    "has_momT = np.transpose(has_momT)\n",
    "word_countT = np.matrix(word_countT)\n",
    "word_countT = np.transpose(word_countT)    \n",
    "count_upperT = np.matrix(count_upperT)\n",
    "count_upperT = np.transpose(count_upperT) \n",
    "count_exclaimT = np.matrix(count_exclaimT)\n",
    "count_exclaimT = np.transpose(count_exclaimT)\n",
    "count_AtTheRateT = np.matrix(count_AtTheRateT)\n",
    "count_AtTheRateT = np.transpose(count_AtTheRateT)\n",
    "count_percentT = np.matrix(count_percentT)\n",
    "count_percentT = np.transpose(count_percentT)\n",
    "count_LeftBracketT = np.matrix(count_LeftBracketT)\n",
    "count_LeftBracketT = np.transpose(count_LeftBracketT)\n",
    "count_QuotesT = np.matrix(count_QuotesT)\n",
    "count_QuotesT = np.transpose(count_QuotesT)\n",
    "count_StarT = np.matrix(count_StarT)\n",
    "count_StarT = np.transpose(count_StarT)\n",
    "count_BackSlashesT = np.matrix(count_BackSlashesT)\n",
    "count_BackSlashesT = np.transpose(count_BackSlashesT)\n",
    "count_FrontSlashT = np.matrix(count_FrontSlashT)\n",
    "count_FrontSlashT = np.transpose(count_FrontSlashT)\n",
    "count_YourT = np.matrix(count_YourT)\n",
    "count_YourT = np.transpose(count_YourT)\n",
    "count_YouT = np.matrix(count_YouT)\n",
    "count_YouT = np.transpose(count_YouT)\n",
    "count_badwordT = np.matrix(count_badwordT)\n",
    "count_badwordT = np.transpose(count_badwordT)\n",
    "\n",
    "X_test_test = np.zeros((len(X_test), 14))\n",
    "lis = [has_momT, word_countT, count_upperT, count_exclaimT, count_AtTheRateT, count_percentT, count_LeftBracketT,\n",
    "         count_QuotesT, count_StarT, count_BackSlashesT, count_FrontSlashT, count_YourT, count_YouT, count_badwordT]\n",
    "for i in [has_momT, word_countT, count_upperT, count_exclaimT, count_AtTheRateT, count_percentT, count_LeftBracketT,\n",
    "         count_QuotesT, count_StarT, count_BackSlashesT, count_FrontSlashT, count_YourT, count_YouT, count_badwordT]:\n",
    "    X_test_tfidf = np.insert(X_test_tfidf, [X_test_tfidf.shape[1]], i, axis=1)\n",
    "\n",
    "for i in range(14):\n",
    "    for j in range(len(X_test)):\n",
    "        X_test_test[j, i] = lis[i][j, 0]\n",
    "    \n",
    "X_test_test = sparse.csr_matrix(X_test_test)\n",
    "X_test_tfidf = sparse.csr_matrix(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(warm_start = True)\n",
    "clf.fit(X_train_tfidf,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  [0.79754861 0.76156584]   Recall:  [0.96571136 0.30880231]    F-score:  [0.87361111 0.43942505]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.97      0.87      1954\n",
      "          1       0.76      0.31      0.44       693\n",
      "\n",
      "avg / total       0.79      0.79      0.76      2647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict_proba(X_test_tfidf)\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "precision, recall, f_score, _ = precision_recall_fscore_support(Y_test, y_pred)\n",
    "\n",
    "print('Precision: ', precision, '  Recall: ', recall, '   F-score: ', f_score)\n",
    "\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**False Postives** : 59<br>**False Negatives** : 448"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy** : 0<br>**AUC Score** : 0.8243740224292937"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count = 0\n",
    "# for prediction in range(len(predictions)):\n",
    "#     if predictions[prediction] == Y_test[prediction]:\n",
    "#         count += 1\n",
    "# acc = count/len(predictions)\n",
    "# aoc = metrics.roc_auc_score(Y_test,predictions)\n",
    "# data = \"**Accuracy** : \" + str(acc) + \"<br>\" + \"**AOC Score** : \" + str(aoc) \n",
    "# display(Markdown(data))\n",
    "final = []\n",
    "for prediction in predictions:\n",
    "    final.append(prediction[1])\n",
    "\n",
    "fpCount = 0\n",
    "fp = open(\"Error Analysis/RandomForest-FalsePositives.csv\",\"w\") \n",
    "for index in range(len(final)):\n",
    "    if (final[index] > 0.5 and Y_test[index] == 0):\n",
    "        fp.write(str(final[index]) + \",\" + X_test[index])\n",
    "        fp.write(\"\\n\")\n",
    "        fpCount += 1\n",
    "fp.close()\n",
    "\n",
    "fnCount = 0\n",
    "fn = open(\"Error Analysis/RandomForest-FalseNegatives.csv\",\"w\") \n",
    "for index in range(len(final)):\n",
    "    if (final[index] <= 0.5 and Y_test[index] == 1):\n",
    "        fn.write(str(final[index]) + \",\" + X_test[index])\n",
    "        fn.write(\"\\n\")\n",
    "        fnCount += 1\n",
    "fn.close()\n",
    "counts = \"**False Postives** : \" + str(fpCount) + \"<br>\" + \"**False Negatives** : \" + str(fnCount)\n",
    "display(Markdown(counts))\n",
    "acc = 0\n",
    "aoc = metrics.roc_auc_score(Y_test,final)\n",
    "data = \"**Accuracy** : \" + str(acc) + \"<br>\" + \"**AUC Score** : \" + str(aoc) \n",
    "display(Markdown(data))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

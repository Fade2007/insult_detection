{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../Preprocessed Data/cleaned_dataset_train.csv')\n",
    "df_test = pd.read_csv('../Preprocessed Data/cleaned_dataset_test.csv')\n",
    "#df = pd.read_csv('../cleaned_dataset.csv')\n",
    "#df_train[\"comment\"].fillna(\" \").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['comment'].fillna(\" \").tolist()\n",
    "Y_train = df_train['insult'].tolist()\n",
    "\n",
    "X_test = df_test['comment'].fillna(\" \").tolist()\n",
    "Y_test = df_test['insult'].tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "global_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasYourMom(sentence):\n",
    "    return sentence.lower().count(\"your mom\")\n",
    "\n",
    "def wordCount(sentence):\n",
    "    return len(sentence.split())\n",
    "\n",
    "def countUpper(sentence):\n",
    "    return float(sum(1 for k in sentence if k.isupper()))/len(sentence)\n",
    "\n",
    "def countExclaim(sentence):\n",
    "    return float(sentence.count('!')/float(len(sentence)))\n",
    "\n",
    "def countAtTheRate(sentence):\n",
    "    return float(sentence.count('@')/float(len(sentence)))\n",
    "\n",
    "def countPercent(sentence):\n",
    "    return float(sentence.count('%')/float(len(sentence)))\n",
    "\n",
    "def countLeftBracket(sentence):\n",
    "    return float(sentence.count('(')/float(len(sentence)))\n",
    "\n",
    "def countQuotes(sentence):\n",
    "    return float(sentence.count('\"')/float(len(sentence)))\n",
    "\n",
    "def countStar(sentence):\n",
    "    return float(sentence.count('*')/float(len(sentence)))\n",
    "\n",
    "def countBackSlashes(sentence):\n",
    "    return float(sentence.count('\\\\')/float(len(sentence)))\n",
    "\n",
    "def countFrontSlash(sentence):\n",
    "    return float(sentence.count('/')/float(len(sentence)))\n",
    "\n",
    "def percentCapital(sentence):\n",
    "    upper = 0\n",
    "    total_count = 0\n",
    "    for word in sentence:\n",
    "        total_count += 1\n",
    "        if word.isupper():\n",
    "            upper += 1\n",
    "    return upper/total_count\n",
    "\n",
    "\n",
    "def percentSpecial(sentence):\n",
    "    global_count = 0\n",
    "    global_count += countExclaim(sentence)\n",
    "    #global_count += countFrontSlash(sentence)\n",
    "    #global_count += countBackSlashes(sentence)\n",
    "    #global_count += countQuotes(sentence)\n",
    "    global_count += countPercent(sentence)\n",
    "    global_count += countAtTheRate(sentence)\n",
    "\n",
    "    return global_count/len(sentence)\n",
    "            \n",
    "\n",
    "def countYour(sentence):\n",
    "    s = 0\n",
    "    lst = ['your','Your','YOUR']\n",
    "    for word in lst:\n",
    "        s += sentence.count(word)\n",
    "    return float(s)/len(sentence)\n",
    "\n",
    "def countYou(sentence):\n",
    "    s = 0\n",
    "    lst = ['you','You','YOU']\n",
    "    for word in lst:\n",
    "        s += sentence.count(word)\n",
    "    return float(s)/len(sentence)\n",
    "\n",
    "def countBadWords(sentence):\n",
    "    tmp = sentence.lower()\n",
    "    badWordCount = 0\n",
    "    badWordFile = open(\"../compiled_badword_list.txt\",\"r\")\n",
    "    badWordList = badWordFile.readlines()\n",
    "    for badWord in badWordList:\n",
    "        bw = badWord.lower()\n",
    "        if bw[:-1] in tmp:\n",
    "            badWordCount += 1\n",
    "    #print(len(sentence.split()))\n",
    "    try:\n",
    "        return badWordCount/len(sentence.split())\n",
    "    except:\n",
    "        return badWordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train['comment'].fillna(\" \").tolist()\n",
    "Y_train = df_train['insult'].tolist()\n",
    "X_test = df_test['comment'].fillna(\" \").tolist()\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "X_train_tfidf = vectorizer.transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf = X_train_tfidf.todense()\n",
    "X_test_tfidf = X_test_tfidf.todense()\n",
    "\n",
    "has_mom = []\n",
    "word_count = []\n",
    "count_upper = []\n",
    "count_exclaim = []\n",
    "count_AtTheRate = []\n",
    "count_percent = []\n",
    "count_LeftBracket = []\n",
    "count_Quotes = []\n",
    "count_Star = []\n",
    "count_BackSlashes = []\n",
    "count_FrontSlash = []\n",
    "count_Your = []\n",
    "count_You = []\n",
    "count_badword = []\n",
    "count_percentSpecial = []\n",
    "count_percentCapital = []\n",
    "for sentence in X_train:\n",
    "    has_mom.append(hasYourMom(sentence))\n",
    "    word_count.append(wordCount(sentence))\n",
    "    count_upper.append(countUpper(sentence))\n",
    "    count_exclaim.append(countExclaim(sentence))\n",
    "    count_AtTheRate.append(countAtTheRate(sentence))\n",
    "    count_percent.append(countPercent(sentence))\n",
    "    count_LeftBracket.append(countLeftBracket(sentence))\n",
    "    count_Quotes.append(countQuotes(sentence))\n",
    "    count_Star.append(countStar(sentence))\n",
    "    count_BackSlashes.append(countBackSlashes(sentence))\n",
    "    count_FrontSlash.append(countFrontSlash(sentence))\n",
    "    count_Your.append(countYour(sentence))\n",
    "    count_You.append(countYou(sentence))\n",
    "    count_badword.append(countBadWords(sentence))\n",
    "    count_percentSpecial.append(percentSpecial(sentence))\n",
    "    count_percentCapital.append(percentCapital(sentence))\n",
    "    \n",
    "    \n",
    "has_mom = np.matrix(has_mom)\n",
    "has_mom = np.transpose(has_mom)\n",
    "word_count = np.matrix(word_count)\n",
    "word_count = np.transpose(word_count)    \n",
    "count_upper = np.matrix(count_upper)\n",
    "count_upper = np.transpose(count_upper) \n",
    "count_exclaim = np.matrix(count_exclaim)\n",
    "count_exclaim = np.transpose(count_exclaim)\n",
    "count_AtTheRate = np.matrix(count_AtTheRate)\n",
    "count_AtTheRate = np.transpose(count_AtTheRate)\n",
    "count_percent = np.matrix(count_percent)\n",
    "count_percent = np.transpose(count_percent)\n",
    "count_LeftBracket = np.matrix(count_LeftBracket)\n",
    "count_LeftBracket = np.transpose(count_LeftBracket)\n",
    "count_Quotes = np.matrix(count_Quotes)\n",
    "count_Quotes = np.transpose(count_Quotes)\n",
    "count_Star = np.matrix(count_Star)\n",
    "count_Star = np.transpose(count_Star)\n",
    "count_BackSlashes = np.matrix(count_BackSlashes)\n",
    "count_BackSlashes = np.transpose(count_BackSlashes)\n",
    "count_FrontSlash = np.matrix(count_FrontSlash)\n",
    "count_FrontSlash = np.transpose(count_FrontSlash)\n",
    "count_Your = np.matrix(count_Your)\n",
    "count_Your = np.transpose(count_Your)\n",
    "count_You = np.matrix(count_You)\n",
    "count_You = np.transpose(count_You)\n",
    "count_badword = np.matrix(count_badword)\n",
    "count_badword = np.transpose(count_badword)\n",
    "count_percentSpecial = np.matrix(count_percentSpecial)\n",
    "count_percentSpecial = np.transpose(count_percentSpecial)\n",
    "count_percentCapital = np.matrix(count_percentCapital)\n",
    "count_percentCapital = np.transpose(count_percentCapital)\n",
    "\n",
    "X_train_train = np.zeros((3947, 16))\n",
    "#count_Your, count_You, count_badword, \n",
    "for i in [has_mom, word_count, count_upper, count_exclaim, count_AtTheRate, count_percent, count_LeftBracket,\n",
    "         count_Quotes, count_Star, count_BackSlashes, count_FrontSlash, count_Your, count_You, count_badword,\n",
    "          count_percentCapital, count_percentSpecial]:\n",
    "    X_train_tfidf = np.insert(X_train_tfidf, [X_train_tfidf.shape[1]], i, axis=1)\n",
    "    \n",
    "lis = [has_mom, word_count, count_upper, count_exclaim, count_AtTheRate, count_percent, count_LeftBracket,\n",
    "         count_Quotes, count_Star, count_BackSlashes, count_FrontSlash, count_Your, count_You, count_badword, \n",
    "      count_percentCapital, count_percentSpecial]\n",
    "\n",
    "#print(has_mom.shape) \n",
    "print(lis[0][10, 0])\n",
    "for i in range(16):\n",
    "    for j in range(3947):\n",
    "        X_train_train[j, i] = lis[i][j, 0]\n",
    "\n",
    "X_train_train = sparse.csr_matrix(X_train_train)\n",
    "X_train_tfidf = sparse.csr_matrix(X_train_tfidf)\n",
    "\n",
    "has_momT = []\n",
    "word_countT = []\n",
    "count_upperT = []\n",
    "count_exclaimT = []\n",
    "count_AtTheRateT = []\n",
    "count_percentT = []\n",
    "count_LeftBracketT = []\n",
    "count_QuotesT = []\n",
    "count_StarT = []\n",
    "count_BackSlashesT = []\n",
    "count_FrontSlashT = []\n",
    "count_YourT = []\n",
    "count_YouT = []\n",
    "count_badwordT = []\n",
    "count_percentSpecialT = []\n",
    "count_percentCapitalT = []\n",
    "for sentence in X_test:\n",
    "    has_momT.append(hasYourMom(sentence))\n",
    "    word_countT.append(wordCount(sentence))\n",
    "    count_upperT.append(countUpper(sentence))\n",
    "    count_exclaimT.append(countExclaim(sentence))\n",
    "    count_AtTheRateT.append(countAtTheRate(sentence))\n",
    "    count_percentT.append(countPercent(sentence))\n",
    "    count_LeftBracketT.append(countLeftBracket(sentence))\n",
    "    count_QuotesT.append(countQuotes(sentence))\n",
    "    count_StarT.append(countStar(sentence))\n",
    "    count_BackSlashesT.append(countBackSlashes(sentence))\n",
    "    count_FrontSlashT.append(countFrontSlash(sentence))\n",
    "    count_YourT.append(countYour(sentence))\n",
    "    count_YouT.append(countYou(sentence))\n",
    "    count_badwordT.append(countBadWords(sentence))\n",
    "    count_percentSpecialT.append(percentSpecial(sentence))\n",
    "    count_percentCapitalT.append(percentCapital(sentence))\n",
    "    \n",
    "    \n",
    "has_momT = np.matrix(has_momT)\n",
    "has_momT = np.transpose(has_momT)\n",
    "word_countT = np.matrix(word_countT)\n",
    "word_countT = np.transpose(word_countT)    \n",
    "count_upperT = np.matrix(count_upperT)\n",
    "count_upperT = np.transpose(count_upperT) \n",
    "count_exclaimT = np.matrix(count_exclaimT)\n",
    "count_exclaimT = np.transpose(count_exclaimT)\n",
    "count_AtTheRateT = np.matrix(count_AtTheRateT)\n",
    "count_AtTheRateT = np.transpose(count_AtTheRateT)\n",
    "count_percentT = np.matrix(count_percentT)\n",
    "count_percentT = np.transpose(count_percentT)\n",
    "count_LeftBracketT = np.matrix(count_LeftBracketT)\n",
    "count_LeftBracketT = np.transpose(count_LeftBracketT)\n",
    "count_QuotesT = np.matrix(count_QuotesT)\n",
    "count_QuotesT = np.transpose(count_QuotesT)\n",
    "count_StarT = np.matrix(count_StarT)\n",
    "count_StarT = np.transpose(count_StarT)\n",
    "count_BackSlashesT = np.matrix(count_BackSlashesT)\n",
    "count_BackSlashesT = np.transpose(count_BackSlashesT)\n",
    "count_FrontSlashT = np.matrix(count_FrontSlashT)\n",
    "count_FrontSlashT = np.transpose(count_FrontSlashT)\n",
    "count_YourT = np.matrix(count_YourT)\n",
    "count_YourT = np.transpose(count_YourT)\n",
    "count_YouT = np.matrix(count_YouT)\n",
    "count_YouT = np.transpose(count_YouT)\n",
    "count_badwordT = np.matrix(count_badwordT)\n",
    "count_badwordT = np.transpose(count_badwordT)\n",
    "count_percentSpecialT = np.matrix(count_percentSpecialT)\n",
    "count_percentSpecialT = np.transpose(count_percentSpecialT)\n",
    "count_percentCapitalT = np.matrix(count_percentCapitalT)\n",
    "count_percentCapitalT = np.transpose(count_percentCapitalT)\n",
    "\n",
    "X_test_test = np.zeros((len(X_test), 16))\n",
    "lis = [has_momT, word_countT, count_upperT, count_exclaimT, count_AtTheRateT, count_percentT, count_LeftBracketT,\n",
    "         count_QuotesT, count_StarT, count_BackSlashesT, count_FrontSlashT, count_YourT, count_YouT, count_badwordT,\n",
    "      count_percentCapitalT, count_percentSpecialT]\n",
    "for i in [has_momT, word_countT, count_upperT, count_exclaimT, count_AtTheRateT, count_percentT, count_LeftBracketT,\n",
    "         count_QuotesT, count_StarT, count_BackSlashesT, count_FrontSlashT, count_YourT, count_YouT, count_badwordT,\n",
    "         count_percentCapitalT, count_percentSpecialT]:\n",
    "    X_test_tfidf = np.insert(X_test_tfidf, [X_test_tfidf.shape[1]], i, axis=1)\n",
    "\n",
    "for i in range(16):\n",
    "    for j in range(len(X_test)):\n",
    "        X_test_test[j, i] = lis[i][j, 0]\n",
    "    \n",
    "X_test_test = sparse.csr_matrix(X_test_test)\n",
    "X_test_tfidf = sparse.csr_matrix(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=3, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=True)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(C = 3, class_weight=\"balanced\",warm_start=True)\n",
    "clf.fit(X_train_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(X_test_test)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**False Postives** : 337<br>**False Negatives** : 280"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy** : 0<br>**AUC Score** : 0.8075631294669166"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count = 0\n",
    "# for prediction in range(len(predictions)):\n",
    "#     if predictions[prediction] == Y_test[prediction]:\n",
    "#         count += 1\n",
    "# acc = count/len(predictions)\n",
    "# aoc = metrics.roc_auc_score(Y_test,predictions)\n",
    "# data = \"**Accuracy** : \" + str(acc) + \"<br>\" + \"**AOC Score** : \" + str(aoc) \n",
    "# display(Markdown(data))\n",
    "final = []\n",
    "for prediction in predictions:\n",
    "    final.append(prediction[1])\n",
    "\n",
    "fpCount = 0\n",
    "fp = open(\"Error Analysis/LogisticRegression_OurFeaturesOnly-FalsePositives.csv\",\"w\") \n",
    "for index in range(len(final)):\n",
    "    if (final[index] > 0.5 and Y_test[index] == 0):\n",
    "        temp_sent = X_test[index].replace(',', '')\n",
    "        fp.write(str(final[index]) + \",\" + temp_sent)\n",
    "        fp.write(\"\\n\")\n",
    "        fpCount += 1\n",
    "fp.close()\n",
    "\n",
    "fnCount = 0\n",
    "fn = open(\"Error Analysis/LogisticRegression_OurFeaturesOnly-FalseNegatives.csv\",\"w\") \n",
    "for index in range(len(final)):\n",
    "    if (final[index] <= 0.5 and Y_test[index] == 1):\n",
    "        temp_sent = X_test[index].replace(',', '')\n",
    "        fn.write(str(final[index]) + \",\" + temp_sent)\n",
    "        fn.write(\"\\n\")\n",
    "        fnCount += 1\n",
    "fn.close()\n",
    "counts = \"**False Postives** : \" + str(fpCount) + \"<br>\" + \"**False Negatives** : \" + str(fnCount)\n",
    "display(Markdown(counts))\n",
    "acc = 0\n",
    "aoc = metrics.roc_auc_score(Y_test,final)\n",
    "data = \"**Accuracy** : \" + str(acc) + \"<br>\" + \"**AUC Score** : \" + str(aoc) \n",
    "display(Markdown(data))              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  [0.85239852 0.55066667]   Recall:  [0.82753327 0.5959596 ]    F-score:  [0.83978187 0.57241857]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      1954\n",
      "           1       0.55      0.60      0.57       693\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      2647\n",
      "   macro avg       0.70      0.71      0.71      2647\n",
      "weighted avg       0.77      0.77      0.77      2647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test_test)  \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "precision, recall, f_score, _ = precision_recall_fscore_support(Y_test, predictions)\n",
    "\n",
    "print('Precision: ', precision, '  Recall: ', recall, '   F-score: ', f_score)\n",
    "\n",
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.06879611]), array([0.00039708]))\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "temp_test = X_test_test.todense()\n",
    "print(scipy.stats.pearsonr(temp_test[:, 0], np.transpose(np.matrix(Y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.07897805]), array([6.76476349e-07]))\n"
     ]
    }
   ],
   "source": [
    "temp_train = X_train_train.todense()\n",
    "print(scipy.stats.pearsonr(temp_train[:, 0], np.transpose(np.matrix(Y_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.07897805]), array([6.76476349e-07]))\n",
      "(array([-0.06254075]), array([8.43343984e-05]))\n",
      "(array([0.06155961]), array([0.00010886]))\n",
      "(array([0.01769467]), array([0.26639397]))\n",
      "(array([-0.08058004]), array([3.99713176e-07]))\n",
      "(array([-0.01717569]), array([0.28067551]))\n",
      "(array([nan]), array([1.]))\n",
      "(array([nan]), array([1.]))\n",
      "(array([0.01355944]), array([0.39441226]))\n",
      "(array([-0.0318547]), array([0.04537617]))\n",
      "(array([0.00245153]), array([0.87763403]))\n",
      "(array([0.16494708]), array([1.78867442e-25]))\n",
      "(array([0.34027699]), array([1.42335339e-107]))\n",
      "(array([0.20115177]), array([2.60261058e-37]))\n",
      "(array([0.06155961]), array([0.00010886]))\n",
      "(array([-0.01378576]), array([0.38656737]))\n",
      "(array([0.07897805]), array([6.76476349e-07]))\n",
      "(array([-0.06254075]), array([8.43343984e-05]))\n",
      "(array([0.06155961]), array([0.00010886]))\n",
      "(array([0.01769467]), array([0.26639397]))\n",
      "(array([-0.08058004]), array([3.99713176e-07]))\n",
      "(array([-0.01717569]), array([0.28067551]))\n",
      "(array([nan]), array([1.]))\n",
      "(array([nan]), array([1.]))\n",
      "(array([0.01355944]), array([0.39441226]))\n",
      "(array([-0.0318547]), array([0.04537617]))\n",
      "(array([0.00245153]), array([0.87763403]))\n",
      "(array([0.16494708]), array([1.78867442e-25]))\n",
      "(array([0.34027699]), array([1.42335339e-107]))\n",
      "(array([0.20115177]), array([2.60261058e-37]))\n",
      "(array([0.06155961]), array([0.00010886]))\n",
      "(array([-0.01378576]), array([0.38656737]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3010: RuntimeWarning: invalid value encountered in true_divide\n",
      "  r = r_num / r_den\n"
     ]
    }
   ],
   "source": [
    "for i in range(temp_train.shape[1]):\n",
    "    print(scipy.stats.pearsonr(temp_train[:, i], np.transpose(np.matrix(Y_train))))\n",
    "    \n",
    "for i in range(temp_train.shape[1]):\n",
    "    print(scipy.stats.pearsonr(temp_train[:, i], np.transpose(np.matrix(Y_train))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.06879611]), array([0.00039708]))\n",
      "(array([-0.08376278]), array([1.59559201e-05]))\n",
      "(array([0.06354339]), array([0.00107166]))\n",
      "(array([0.01980222]), array([0.30847687]))\n",
      "(array([-0.06627731]), array([0.00064478]))\n",
      "(array([-0.02754746]), array([0.1565155]))\n",
      "(array([nan]), array([1.]))\n",
      "(array([nan]), array([1.]))\n",
      "(array([0.04536217]), array([0.01959901]))\n",
      "(array([-0.06413898]), array([0.00096091]))\n",
      "(array([-0.00631924]), array([0.74520526]))\n",
      "(array([0.19814095]), array([7.69394689e-25]))\n",
      "(array([0.37921145]), array([2.75852121e-91]))\n",
      "(array([0.25067009]), array([3.27799189e-39]))\n",
      "(array([0.06354339]), array([0.00107166]))\n",
      "(array([0.00101719]), array([0.95828253]))\n",
      "(array([0.06879611]), array([0.00039708]))\n",
      "(array([-0.08376278]), array([1.59559201e-05]))\n",
      "(array([0.06354339]), array([0.00107166]))\n",
      "(array([0.01980222]), array([0.30847687]))\n",
      "(array([-0.06627731]), array([0.00064478]))\n",
      "(array([-0.02754746]), array([0.1565155]))\n",
      "(array([nan]), array([1.]))\n",
      "(array([nan]), array([1.]))\n",
      "(array([0.04536217]), array([0.01959901]))\n",
      "(array([-0.06413898]), array([0.00096091]))\n",
      "(array([-0.00631924]), array([0.74520526]))\n",
      "(array([0.19814095]), array([7.69394689e-25]))\n",
      "(array([0.37921145]), array([2.75852121e-91]))\n",
      "(array([0.25067009]), array([3.27799189e-39]))\n",
      "(array([0.06354339]), array([0.00107166]))\n",
      "(array([0.00101719]), array([0.95828253]))\n"
     ]
    }
   ],
   "source": [
    "for i in range(temp_test.shape[1]):\n",
    "    print(scipy.stats.pearsonr(temp_test[:, i], np.transpose(np.matrix(Y_test))))\n",
    "    \n",
    "for i in range(temp_test.shape[1]):\n",
    "    print(scipy.stats.pearsonr(temp_test[:, i], np.transpose(np.matrix(Y_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'ih ih iwahs af'\n",
    "len(a.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
